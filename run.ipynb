{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatially-Aware Just-in-Time Autoregressive Diffusion\n",
    "\n",
    "Convert an image into patches\n",
    "\n",
    "Apply noise jointly across spatial and temporal domains onto patches\n",
    "\n",
    "Predict the noise \n",
    "\n",
    "Lock in cell in the center and save that as the image\n",
    "\n",
    "150 step diffusion\n",
    "\n",
    "150   1        150\n",
    "\n",
    "past  current  future\n",
    "\n",
    "Technically this is doing two step attending - one attending only for past - creating cond sequence\n",
    "\n",
    "cond sequence then fed into future attending to generate diffusion results\n",
    "\n",
    "Autoregressive Diffusion inference speed sped up from O(nm) to O(n+m)!!!\n",
    "\n",
    "# TODO\n",
    "\n",
    "Implement EMA\n",
    "Double check parts deviating from Lucid's implementation\n",
    "- difformer line 293 to 310\n",
    "Implement position embedding / absolute position embedding\n",
    "- Sinusiodal embeddings need to be updated to work with multi-timestep logic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "PATCH_SIZE = 8\n",
    "SAMPLE_STEPS = 150\n",
    "WINDOW_SIZE = SAMPLE_STEPS\n",
    "SAMPLE_SIZE = 1024\n",
    "data_path = \"../data/jpg/image_00001.jpg\"\n",
    "label_path = \"../data/jpg/imagelabels.mat\"\n",
    "device = \"cuda\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8189/8189 [00:15<00:00, 537.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from einops import rearrange\n",
    "\n",
    "def img_norm(img):\n",
    "    return img / 255\n",
    "\n",
    "def img_crop(img, patch_size):\n",
    "    height= (img.shape[0]//patch_size)*patch_size\n",
    "    width = (img.shape[1]//patch_size)*patch_size\n",
    "    plen = (img.shape[0]//patch_size) * (img.shape[1]//patch_size)\n",
    "    return img[:height, :width, :], plen\n",
    "\n",
    "def get_dataset(root, label_path, patch_size, sample_steps):\n",
    "    labels = scipy.io.loadmat(label_path)\n",
    "    labels = labels['labels'][0]\n",
    "    dataset = []\n",
    "    l = []\n",
    "    for i, idx in enumerate(tqdm(labels)):\n",
    "        fp = root +\"image_\"+str(i+1).rjust(5,'0')+\".jpg\"\n",
    "        f = open(fp, 'rb')\n",
    "        image = Image.open(f)\n",
    "        image, plen = img_crop(np.array(image), patch_size)\n",
    "\n",
    "        mask = [0] * (plen+sample_steps)\n",
    "        mask[1:plen+1] = [i+3 for i in range(plen)]\n",
    "        mask[0] = 1\n",
    "        mask[plen] = 2\n",
    "        mask = np.pad(mask, (sample_steps,0), mode=\"constant\", constant_values=0)\n",
    "\n",
    "        dataset.append(\n",
    "            {\n",
    "                'img':image,\n",
    "                'label':idx,\n",
    "                'mask':mask,\n",
    "                'plen':plen\n",
    "            }\n",
    "        )\n",
    "        del mask\n",
    "        del image\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "# Oxford flowers dataset \n",
    "class FlowerDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 patch_size = 8,\n",
    "                 sample_steps = 99,\n",
    "                 label_path = \"../data/jpg/imagelabels.mat\", \n",
    "                 root = \"../data/jpg/\"):\n",
    "        self.dataset = get_dataset(root, label_path, patch_size, sample_steps)\n",
    "        self.sample_steps = sample_steps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        plen = self.dataset[idx]['plen']\n",
    "        offset = np.random.randint(self.sample_steps+1,  self.sample_steps + plen-1)\n",
    "        return {\n",
    "            'img': self.dataset[idx]['img'],\n",
    "            'mask': self.dataset[idx]['mask'],\n",
    "            'label': self.dataset[idx]['label'] - 1,\n",
    "            'offset':offset\n",
    "        }\n",
    "    \n",
    "trainset = FlowerDataset(patch_size = PATCH_SIZE , sample_steps = SAMPLE_STEPS)\n",
    "# I don't want to pad / resize shit in lazy dataloading- so batch size 1 for now...\n",
    "trainloader = DataLoader(trainset, batch_size=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArSpImageDiffusion(\n",
       "  (model): ArSpDiffusion(\n",
       "    (label_embedding): Embedding(102, 1024)\n",
       "    (proj_in): Linear(in_features=192, out_features=1024, bias=True)\n",
       "    (transformer): Decoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (4): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (5): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (6): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (7): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (8): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (9): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (10): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (11): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (12): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (13): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (14): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (15): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "      )\n",
       "      (adaptive_mlp): Identity()\n",
       "      (final_norm): LayerNorm(\n",
       "        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "      )\n",
       "      (skip_combines): ModuleList(\n",
       "        (0-15): 16 x None\n",
       "      )\n",
       "    )\n",
       "    (denoiser): DenoiseViT(\n",
       "      (to_patch_embedding): Sequential(\n",
       "        (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=192, out_features=256, bias=True)\n",
       "        (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (to_time_emb): Sequential(\n",
       "        (0): LearnedSinusoidalPosEmb()\n",
       "        (1): Linear(in_features=1025, out_features=256, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (transformer): Transformer(\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x ModuleList(\n",
       "            (0): Attention(\n",
       "              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attend): Softmax(dim=-1)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (to_qkv): Linear(in_features=256, out_features=2304, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "                (1): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (2): GELU(approximate='none')\n",
       "                (3): Dropout(p=0.1, inplace=False)\n",
       "                (4): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (5): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (to_denoise): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1024, out_features=192, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (diffusion): ArSpElucidatedDiffusion(\n",
       "      (net): DenoiseViT(\n",
       "        (to_patch_embedding): Sequential(\n",
       "          (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=192, out_features=256, bias=True)\n",
       "          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (to_time_emb): Sequential(\n",
       "          (0): LearnedSinusoidalPosEmb()\n",
       "          (1): Linear(in_features=1025, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (transformer): Transformer(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (layers): ModuleList(\n",
       "            (0-5): 6 x ModuleList(\n",
       "              (0): Attention(\n",
       "                (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (attend): Softmax(dim=-1)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (to_qkv): Linear(in_features=256, out_features=2304, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                  (2): GELU(approximate='none')\n",
       "                  (3): Dropout(p=0.1, inplace=False)\n",
       "                  (4): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  (5): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (2): Linear(in_features=1024, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (to_denoise): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=1024, out_features=192, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_tokens): Rearrange('b (h p1) (w p2) c -> b (h w) (p1 p2 c)', p1=8, p2=8)\n",
       "  (to_image): Rearrange('b (h w) (p1 p2 c) -> b (h p1) (w p2) c', p1=8, p2=8, h=32)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from difformer import ArSpImageDiffusion\n",
    "import torch\n",
    "\n",
    "model = ArSpImageDiffusion(\n",
    "    model = dict(\n",
    "        dim = 1024,\n",
    "    ),\n",
    "    patch_size = PATCH_SIZE,\n",
    "    num_classes = 102,\n",
    "    window_size = WINDOW_SIZE,\n",
    "    sample_steps = SAMPLE_STEPS,\n",
    "    sample_size = SAMPLE_SIZE\n",
    ")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    total_steps = 0\n",
    "    for i, b in enumerate(tqdm(dataloader)):\n",
    "        img = b['img'].to(device).float()\n",
    "        mask = b['mask'].to(device).int()\n",
    "        label = b['label'].to(device).int()\n",
    "        offset = int(b['offset'])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(img, mask, offset, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        total_steps += 1\n",
    "    return running_loss/total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, num_images):\n",
    "    model.eval()\n",
    "    for l in tqdm(range(101)):\n",
    "        for j in range(num_images):\n",
    "            sampled = model.sample(batch_size = 1, label=torch.tensor(l).to(device))\n",
    "            img = Image.fromarray(sampled.squeeze().cpu().numpy(), 'RGB')\n",
    "            img.save(\"./results/\"+str(l)+\"_\"+str(j)+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 6215/8189 [03:34<01:08, 28.95it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 6\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m e \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      9\u001b[0m         inference(model, \u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m label \u001b[38;5;241m=\u001b[39m b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mint()\n\u001b[1;32m      9\u001b[0m offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffset\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m SAMPLE_STEPS \u001b[38;5;241m<\u001b[39m offset\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m offset \u001b[38;5;241m<\u001b[39m mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m SAMPLE_STEPS\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "epochs = 5000\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "for e in range(epochs):\n",
    "    loss = train(model, trainloader, optimizer)\n",
    "    \n",
    "    if e % 100 == 0 and e > 0:\n",
    "        inference(model, 5)\n",
    "\n",
    "    print(e, \" avg loss:{:.3f}\".format(loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jitdiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
