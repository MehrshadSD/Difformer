{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatially-Aware Just-in-Time Autoregressive Diffusion\n",
    "\n",
    "Convert an image into patches\n",
    "\n",
    "Apply noise jointly across spatial and temporal domains onto patches\n",
    "\n",
    "Predict the noise \n",
    "\n",
    "Lock in cell in the center and save that as the image\n",
    "\n",
    "150 step diffusion\n",
    "\n",
    "150   1        150\n",
    "\n",
    "past  current  future\n",
    "\n",
    "Technically this is doing two step attending - one attending only for past - creating cond sequence\n",
    "\n",
    "cond sequence then fed into future attending to generate diffusion results\n",
    "\n",
    "Autoregressive Diffusion inference speed sped up from O(nm) to O(n+m)!!!\n",
    "\n",
    "# TODO\n",
    "\n",
    "Implement EMA\n",
    "Double check parts deviating from Lucid's implementation\n",
    "- difformer line 293 to 310\n",
    "Implement position embedding / absolute position embedding\n",
    "- Sinusiodal embeddings need to be updated to work with multi-timestep logic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "PATCH_SIZE = 8\n",
    "SAMPLE_STEPS = 150\n",
    "WINDOW_SIZE = SAMPLE_STEPS\n",
    "SAMPLE_SIZE = 1024\n",
    "data_path = \"../data/jpg/image_00001.jpg\"\n",
    "label_path = \"../data/jpg/imagelabels.mat\"\n",
    "device = \"cuda\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1450/8189 [00:02<00:12, 546.82it/s]"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from einops import rearrange\n",
    "\n",
    "def img_norm(img):\n",
    "    return img / 255\n",
    "\n",
    "def img_crop(img, patch_size):\n",
    "    height= (img.shape[0]//patch_size)*patch_size\n",
    "    width = (img.shape[1]//patch_size)*patch_size\n",
    "    plen = (img.shape[0]//patch_size) * (img.shape[1]//patch_size)\n",
    "    return img[:height, :width, :], plen\n",
    "\n",
    "def get_dataset(root, label_path, patch_size, sample_steps):\n",
    "    labels = scipy.io.loadmat(label_path)\n",
    "    labels = labels['labels'][0]\n",
    "    dataset = []\n",
    "    l = []\n",
    "    for i, idx in enumerate(tqdm(labels)):\n",
    "        fp = root +\"image_\"+str(i+1).rjust(5,'0')+\".jpg\"\n",
    "        f = open(fp, 'rb')\n",
    "        image = Image.open(f)\n",
    "        image, plen = img_crop(np.array(image), patch_size)\n",
    "\n",
    "        mask = [0] * (plen+sample_steps)\n",
    "        mask[1:plen+1] = [i+3 for i in range(plen)]\n",
    "        mask[0] = 1\n",
    "        mask[plen] = 2\n",
    "        mask = np.pad(mask, (sample_steps,0), mode=\"constant\", constant_values=0)\n",
    "\n",
    "        dataset.append(\n",
    "            {\n",
    "                'img':image,\n",
    "                'label':idx,\n",
    "                'mask':mask,\n",
    "                'plen':plen\n",
    "            }\n",
    "        )\n",
    "        del mask\n",
    "        del image\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "# Oxford flowers dataset \n",
    "class FlowerDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 patch_size = 8,\n",
    "                 sample_steps = 99,\n",
    "                 label_path = \"../data/jpg/imagelabels.mat\", \n",
    "                 root = \"../data/jpg/\"):\n",
    "        self.dataset = get_dataset(root, label_path, patch_size, sample_steps)\n",
    "        self.sample_steps = sample_steps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        plen = self.dataset[idx]['plen']\n",
    "        offset = np.random.randint(self.sample_steps,  self.sample_steps + plen)\n",
    "        return {\n",
    "            'img': self.dataset[idx]['img'],\n",
    "            'mask': self.dataset[idx]['mask'],\n",
    "            'label': self.dataset[idx]['label'] - 1,\n",
    "            'offset':offset\n",
    "        }\n",
    "    \n",
    "trainset = FlowerDataset(patch_size = PATCH_SIZE , sample_steps = SAMPLE_STEPS)\n",
    "# I don't want to pad / resize shit in lazy dataloading- so batch size 1 for now...\n",
    "trainloader = DataLoader(trainset, batch_size=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArSpImageDiffusion(\n",
       "  (model): ArSpDiffusion(\n",
       "    (label_embedding): Embedding(102, 1024)\n",
       "    (proj_in): Linear(in_features=192, out_features=1024, bias=True)\n",
       "    (transformer): Decoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (4): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (5): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (6): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (7): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (8): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (9): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (10): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (11): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (12): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (13): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (14): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): Attention(\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_k): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_v): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "        (15): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): LayerNorm(\n",
       "              (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "            )\n",
       "            (1-2): 2 x None\n",
       "          )\n",
       "          (1): FeedForward(\n",
       "            (ff): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (1): GELU(approximate='none')\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Residual()\n",
       "        )\n",
       "      )\n",
       "      (adaptive_mlp): Identity()\n",
       "      (final_norm): LayerNorm(\n",
       "        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=False)\n",
       "      )\n",
       "      (skip_combines): ModuleList(\n",
       "        (0-15): 16 x None\n",
       "      )\n",
       "    )\n",
       "    (denoiser): DenoiseViT(\n",
       "      (to_patch_embedding): Sequential(\n",
       "        (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=192, out_features=256, bias=True)\n",
       "        (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (to_time_emb): Sequential(\n",
       "        (0): LearnedSinusoidalPosEmb()\n",
       "        (1): Linear(in_features=1025, out_features=256, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (transformer): Transformer(\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x ModuleList(\n",
       "            (0): Attention(\n",
       "              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attend): Softmax(dim=-1)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (to_qkv): Linear(in_features=256, out_features=2304, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "                (1): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (2): GELU(approximate='none')\n",
       "                (3): Dropout(p=0.1, inplace=False)\n",
       "                (4): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (5): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (to_denoise): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=1024, out_features=192, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (diffusion): ArSpElucidatedDiffusion(\n",
       "      (net): DenoiseViT(\n",
       "        (to_patch_embedding): Sequential(\n",
       "          (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=192, out_features=256, bias=True)\n",
       "          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (to_time_emb): Sequential(\n",
       "          (0): LearnedSinusoidalPosEmb()\n",
       "          (1): Linear(in_features=1025, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (transformer): Transformer(\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (layers): ModuleList(\n",
       "            (0-5): 6 x ModuleList(\n",
       "              (0): Attention(\n",
       "                (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (attend): Softmax(dim=-1)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (to_qkv): Linear(in_features=256, out_features=2304, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                  (2): GELU(approximate='none')\n",
       "                  (3): Dropout(p=0.1, inplace=False)\n",
       "                  (4): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  (5): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (2): Linear(in_features=1024, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (to_denoise): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=1024, out_features=192, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_tokens): Rearrange('b (h p1) (w p2) c -> b (h w) (p1 p2 c)', p1=8, p2=8)\n",
       "  (to_image): Rearrange('b (h w) (p1 p2 c) -> b (h p1) (w p2) c', p1=8, p2=8, h=32)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from difformer import ArSpImageDiffusion\n",
    "import torch\n",
    "\n",
    "model = ArSpImageDiffusion(\n",
    "    model = dict(\n",
    "        dim = 1024,\n",
    "    ),\n",
    "    patch_size = PATCH_SIZE,\n",
    "    num_classes = 102,\n",
    "    window_size = WINDOW_SIZE,\n",
    "    sample_steps = SAMPLE_STEPS,\n",
    "    sample_size = SAMPLE_SIZE\n",
    ")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    total_steps = 0\n",
    "    for i, b in enumerate(tqdm(dataloader)):\n",
    "        img = b['img'].to(device).float()\n",
    "        mask = b['mask'].to(device).int()\n",
    "        label = b['label'].to(device).int()\n",
    "        offset = int(b['offset'])\n",
    "\n",
    "        assert SAMPLE_STEPS < offset\n",
    "        assert offset < mask.shape[1] - SAMPLE_STEPS\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(img, mask, offset, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        total_steps += 1\n",
    "    return running_loss/total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, num_images):\n",
    "    model.eval()\n",
    "    for l in tqdm(range(101)):\n",
    "        for j in range(num_images):\n",
    "            sampled = model.sample(batch_size = 1, label=torch.tensor(l).to(device))\n",
    "            img = Image.fromarray(sampled.squeeze().cpu().numpy(), 'RGB')\n",
    "            img.save(\"./results/\"+str(l)+\"_\"+str(j)+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 748/8189 [00:26<04:20, 28.57it/s]"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "epochs = 5000\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "for e in range(epochs):\n",
    "    loss = train(model, trainloader, optimizer)\n",
    "    \n",
    "    if e % 100 == 0 and e > 0:\n",
    "        inference(model, 5)\n",
    "\n",
    "    print(e, \" avg loss:{:.3f}\".format(loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jitdiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
